{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "#Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dan Saving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Append train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_profiling\n",
    "\n",
    "# train.iloc[:,:10].profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR SELECTING CATEGORICAL AND NUMERICAL VARIABLE\n",
    "def categorical(df):\n",
    "    num=list(df.columns[df.dtypes=='object'])\n",
    "    return num\n",
    "    \n",
    "def numerical(df):\n",
    "    cat=list(df.columns[df.dtypes=='int64'])+list(df.columns[df.dtypes=='float64'])\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = numerical(df_train)\n",
    "print(num,'\\n')\n",
    "print('lenght of numerical variable :',len(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cor=df_train[num].corr()[\"SalePrice\"].sort_values(ascending=False)\n",
    "num_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the variable 'SalePrice' to test with any number\n",
    "df_test['SalePrice']=-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append all data\n",
    "df = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Handling duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking duplicated\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are duplicating data, then you can use this one to drop it\n",
    "# df_drop = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Checking missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for checking missing value\n",
    "def check_missing(df):\n",
    "    percent=df.isnull().sum()/df.shape[0]*100\n",
    "    freq=df.isnull().sum()\n",
    "    types=df.dtypes\n",
    "    df_miss=pd.DataFrame({'percentage':percent, 'frequency':freq, 'var_type':types})\n",
    "    df_miss.sort_values(by='frequency',ascending= False, inplace=True)\n",
    "    return df_miss[df_miss['percentage']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check=check_missing(df)\n",
    "df_check.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Separating target variable & feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "X.drop(['Id','SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d) Defining numerical & categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR SELECTING CATEGORICAL AND NUMERICAL VARIABLE\n",
    "def categorical(df):\n",
    "    num=list(df.columns[df.dtypes=='object'])\n",
    "    return num\n",
    "    \n",
    "def numerical(df):\n",
    "    cat=list(df.columns[df.dtypes=='int64'])+list(df.columns[df.dtypes=='float64'])\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = categorical(X)\n",
    "print(X_cat,'\\n')\n",
    "print('lenght of categorical variable :',len(X_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = numerical(X)\n",
    "print(X_num,'\\n')\n",
    "print('lenght of numerical variable :',len(X_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X_cat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X_num].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=X[X_num]\n",
    "a.loc[234,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### e) Imputation missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation for numerical variable \n",
    "for i in X_num:\n",
    "    X[i].fillna(X[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X_num].loc[234,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation for categorical variable \n",
    "for i in X_cat:\n",
    "    X[i].fillna('no cat',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing(X)\n",
    "#imputation has finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  f) Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X_num].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = StandardScaler()\n",
    "standard.fit(X[X_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = pd.DataFrame(standard.transform(X[X_num]))\n",
    "X_standard.columns = X[X_num].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Var_cat = X[X_cat]\n",
    "Var_cat.loc[234,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### g) One Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1st Data set : X_num + X_cat + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full= pd.concat([X[X_num], X[X_cat],y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2nd Dataset : X_standard + X_cat + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard.reset_index(drop=True, inplace=True)\n",
    "Var_cat.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full= pd.concat([X_standard, Var_cat ,y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking effect of numerical imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train=df_full[df_full['SalePrice']>=0]\n",
    "df_full_test=df_full[df_full['SalePrice']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2 = numerical(df_full_train)\n",
    "print(num2,'\\n')\n",
    "print('lenght of numerical variable :',len(num2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after\n",
    "num_cor2=df_full_train[num2].corr()[\"SalePrice\"].sort_values(ascending=False)\n",
    "num_cor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before\n",
    "num_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full[['KitchenQual','SalePrice']].groupby('KitchenQual').median().sort_values(by='SalePrice',ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['KitchenQualNum']=df_full['KitchenQual'].map({'Ex':4,'Gd':3,'TA':2,'Fa':1,'no cat':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full[['PoolQC','SalePrice']].groupby('PoolQC').median().sort_values(by='SalePrice',ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['PoolQCNum']=df_full['PoolQC'].map({'Ex':3,'Fa':2,'Gd':1,'no cat':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[['Neighborhood','SalePrice']].groupby('Neighborhood').median().sort_values(by='SalePrice',ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['NridgHt', 'NoRidge', 'StoneBr', 'Timber', 'Somerst', 'Veenker',\n",
    "       'Crawfor', 'ClearCr', 'CollgCr', 'Blmngtn', 'NWAmes', 'Gilbert',\n",
    "       'SawyerW', 'Mitchel', 'NPkVill', 'NAmes', 'SWISU', 'Blueste', 'Sawyer',\n",
    "       'BrkSide', 'Edwards', 'OldTown', 'BrDale', 'IDOTRR', 'MeadowV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['NeighborhoodNum']=df_full['Neighborhood'].map({'NridgHt':25,'NoRidge':24,'StoneBr':23,'Timber':22,'Somerst':21,\n",
    "                                             'Veenker':20,'Crawfor':19,'ClearCr':18,'CollgCr':17,'Blmngtn':16,\n",
    "                                             'NMAmes':15,'Gilbert':14,'SawyerW':13,'Mitchel':12,'NPkVill':11,\n",
    "                                             'NAmes':10,'SWISU':9,'Blueste':8,'Sawyer':7,'BrkSide':6,'Edwards':5,\n",
    "                                             'OldTown':4,'Brdale':3,'IDOTRR':2,'MeadowV':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitur_num=['SalePrice',\n",
    " 'OverallQual',\n",
    " 'GrLivArea',\n",
    " 'GarageCars',\n",
    " 'GarageArea',\n",
    " 'TotalBsmtSF',\n",
    " '1stFlrSF',\n",
    " 'FullBath',\n",
    " 'TotRmsAbvGrd',\n",
    " 'YearBuilt',\n",
    " 'YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fitur = fitur_num+['KitchenQualNum','PoolQCNum','NeighborhoodNum']\n",
    "best_fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies=pd.get_dummies(df_full,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_train=df_dummies[df_dummies['SalePrice']>=0]\n",
    "df_dummies_test=df_dummies[df_dummies['SalePrice']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_dummies_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_train.drop('SalePrice',axis=1,inplace=True)\n",
    "df_dummies_test.drop('SalePrice',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_train.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitur=list(df_dummies_train.columns)\n",
    "len(fitur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_dummies_train[fitur],\n",
    "                                                    y,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VIF\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, thresh=5.0, impute=True, impute_strategy='median'):\n",
    "#         # From looking at documentation, values between 5 and 10 are \"okay\".\n",
    "#         # Above 10 is too high and so should be removed.\n",
    "#         self.thresh = thresh\n",
    "        \n",
    "#         # The statsmodel function will fail with NaN values, as such we have to impute them.\n",
    "#         # By default we impute using the median value.\n",
    "#         # This imputation could be taken out and added as part of an sklearn Pipeline.\n",
    "#         if impute:\n",
    "#             self.imputer = Imputer(strategy=impute_strategy)\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         print('ReduceVIF fit')\n",
    "#         if hasattr(self, 'imputer'):\n",
    "#             self.imputer.fit(X)\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         print('ReduceVIF transform')\n",
    "#         columns = X.columns.tolist()\n",
    "#         if hasattr(self, 'imputer'):\n",
    "#             X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n",
    "#         return ReduceVIF.calculate_vif(X, self.thresh)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def calculate_vif(X, thresh=5.0):\n",
    "#         # Taken from https://stats.stackexchange.com/a/253620/53565 and modified\n",
    "#         dropped=True\n",
    "#         while dropped:\n",
    "#             variables = X.columns\n",
    "#             dropped = False\n",
    "#             vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n",
    "            \n",
    "#             max_vif = max(vif)\n",
    "#             if max_vif > thresh:\n",
    "#                 maxloc = vif.index(max_vif)\n",
    "#                 print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n",
    "#                 X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n",
    "#                 dropped=True\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_num[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = ReduceVIF()\n",
    "\n",
    "# # Only use 10 columns for speed in this example\n",
    "# VIF_var = transformer.fit_transform(x_train[X_num], y_train)\n",
    "\n",
    "# VIF_var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kf5=KFold(n_splits=5,random_state=10)\n",
    "\n",
    "def eval(alg,kf,x_train, x_test):\n",
    "    alg.fit(x_train,y_train)\n",
    "    print(\"R2 test: \\n\",alg.score(x_test,y_test),'\\n')\n",
    "    print(\"R2 train: \\n\",alg.score(x_train,y_train),'\\n')\n",
    "    \n",
    "    cvr=cross_val_score(alg,x_train,y_train,cv=kf)\n",
    "    print(\"R2 cv : \\n\",cvr,'\\n')\n",
    "    print(\"R2 cv mean : \\n\",cvr.mean(),'\\n')\n",
    "    print(\"R2 cv std : \\n\",cvr.std(),'\\n')\n",
    "    \n",
    "\n",
    "    resi=alg.predict(x_test)-y_test\n",
    "    plt.scatter(alg.predict(x_test),resi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb = XGBRegressor(learning_rate=0.1,\n",
    "                    n_estimators=40, \n",
    "                    min_child_weight=3,\n",
    "                    max_depth=5,\n",
    "                    gamma=0.1,\n",
    "                    subample=0.8,\n",
    "                    colsample_bytree=0.6,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.1,\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model Ridge regression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model Lasso regression\n",
    "lasso = LassoCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XBG Regressor\n",
    "eval(rexgb,5,x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO Regression\n",
    "eval(lasso,5,x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selected variables\n",
    "coef = pd.Series(lasso.coef_, index = x_train.columns)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_var = list(coef[coef!=0].index)\n",
    "selected_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  3.3 Choosing best model & feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.3 Importance feature of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def feature_importance_df(model,FITUR,k,scale):\n",
    "    model.fit(x_train,y_train)\n",
    "    plt.figure(figsize=(6,10))\n",
    "    sns.set_context(\"paper\", font_scale=scale)\n",
    "    fitur_imp=pd.DataFrame({'fitur':FITUR,'importances':model.feature_importances_})\n",
    "    fitur_imp.sort_values(by='importances',ascending=False,inplace=True)\n",
    "    sns.barplot(x='importances',y='fitur',data=fitur_imp[0:k])\n",
    "    plt.xlabel(\"Feature Importances\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.show()\n",
    "    \n",
    "    return fitur_imp['fitur'][0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = feature_importance_df(rexgb,fitur,30,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling with 30 importance variables\n",
    "eval(rexgb,kf5,x_train[feature_importance], x_test[feature_importance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrmat = x_train[feature_importance].corr()\n",
    "\n",
    "# mask = np.zeros_like(corrmat)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# sns.heatmap(corrmat,vmax=0.8,mask=mask,square=True)\n",
    "# sns.set_context('paper', font_scale=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  3.4 Tunning Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#building function\n",
    "def tunning_result(alg):\n",
    "    print('Best Parameter : \\n', alg.best_params_,'\\n')\n",
    "    print('Best R-Square  : \\n', alg.best_score_,'\\n')\n",
    "    print('Best Model     : \\n', alg.best_estimator_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tunning 1 : n_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_tune = XGBRegressor(learning_rate=0.1,\n",
    "                    #n_estimators=40, \n",
    "                    min_child_weight=3,\n",
    "                    max_depth=5,\n",
    "                    gamma=0.1,\n",
    "                    subample=0.8,\n",
    "                    colsample_bytree=0.6,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.1,\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')\n",
    "\n",
    "select = SelectFromModel(rexgb_tune,threshold='median')\n",
    "\n",
    "pipe = Pipeline([('select',select),('clf',rexgb_tune)])\n",
    "\n",
    "kf5=KFold(n_splits=5,random_state=10)\n",
    "\n",
    "# parameters\n",
    "param_xgb = {\n",
    "    'clf__n_estimators':[20,40,60,80],\n",
    "}\n",
    "\n",
    "rexgb_grid = GridSearchCV(pipe,\n",
    "                          param_grid=param_xgb,\n",
    "                          cv=kf5)\n",
    "rexgb_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_result(rexgb_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_tune2 = XGBRegressor(learning_rate=0.1,\n",
    "                    n_estimators=rexgb_grid.best_params_['clf__n_estimators'], \n",
    "                    #min_child_weight=3,\n",
    "                    #max_depth=5,\n",
    "                    gamma=0.1,\n",
    "                    subample=0.8,\n",
    "                    colsample_bytree=0.6,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.1,\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')\n",
    "\n",
    "select = SelectFromModel(rexgb_tune2,threshold='median')\n",
    "\n",
    "pipe2 = Pipeline([('select',select),('clf',rexgb_tune2)])\n",
    "\n",
    "kf5=KFold(n_splits=5,random_state=10)\n",
    "\n",
    "# parameters\n",
    "param_xgb2 = {\n",
    "    'clf__max_depth':range(3,10,2),\n",
    "    'clf__min_child_weight':range(1,8,2)\n",
    "}\n",
    "\n",
    "rexgb_grid2 = GridSearchCV(pipe2,\n",
    "                          param_grid=param_xgb2,\n",
    "                          cv=kf5)\n",
    "\n",
    "rexgb_grid2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tunning 3 : Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_tune3 = XGBRegressor(learning_rate=0.25,\n",
    "                    n_estimators=rexgb_grid.best_params_['clf__n_estimators'], \n",
    "                    min_child_weight=rexgb_grid2.best_params_['clf__min_child_weight'],\n",
    "                    max_depth=rexgb_grid2.best_params_['clf__max_depth'],\n",
    "                    #gamma=0.1,\n",
    "                    subsample=0.9,\n",
    "                    colsample_bytree=0.6,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.1,\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')\n",
    "\n",
    "select = SelectFromModel(rexgb_tune3,threshold='median')\n",
    "\n",
    "pipe3 = Pipeline([('select',select),('clf',rexgb_tune3)])\n",
    "\n",
    "kf5=KFold(n_splits=5,random_state=10)\n",
    "\n",
    "# parameters\n",
    "param_xgb3 = {\n",
    "    'clf__gamma':[0,0.01,0.1,0.3,0.5,1]}\n",
    "\n",
    "rexgb_grid3 = GridSearchCV(pipe3,\n",
    "                          param_grid=param_xgb3,\n",
    "                          cv=kf5)\n",
    "\n",
    "rexgb_grid3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_result(rexgb_grid3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tuning 4 : Subsample and Colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_tune4 = XGBRegressor(learning_rate=0.25,\n",
    "                    n_estimators=rexgb_grid.best_params_['clf__n_estimators'], \n",
    "                    min_child_weight=rexgb_grid2.best_params_['clf__min_child_weight'],\n",
    "                    max_depth=rexgb_grid2.best_params_['clf__max_depth'],\n",
    "                    gamma=rexgb_grid3.best_params_['clf__gamma'],\n",
    "                    #subsample=0.9,\n",
    "                    #colsample_bytree=0.6,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.1,\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')\n",
    "\n",
    "select = SelectFromModel(rexgb_tune4,threshold='median')\n",
    "\n",
    "pipe4 = Pipeline([('select',select),('clf',rexgb_tune4)])\n",
    "\n",
    "kf5=KFold(n_splits=5,random_state=10)\n",
    "\n",
    "# parameters\n",
    "param_xgb4 = {\n",
    "    'clf__colsample_bytree':[0.5,0.6,0.7,0.8,0.9,1],\n",
    "    'clf__subsample':[0.5,0.6,0.7,0.8,0.9,1]\n",
    "}\n",
    "\n",
    "rexgb_grid4 = GridSearchCV(pipe4,\n",
    "                          param_grid=param_xgb4,\n",
    "                          cv=kf5)\n",
    "\n",
    "rexgb_grid4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_result(rexgb_grid4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tuning 5 : Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_tune5 = XGBRegressor(learning_rate=0.25,\n",
    "                    n_estimators=rexgb_grid.best_params_['clf__n_estimators'], \n",
    "                    min_child_weight=rexgb_grid2.best_params_['clf__min_child_weight'],\n",
    "                    max_depth=rexgb_grid2.best_params_['clf__max_depth'],\n",
    "                    gamma=rexgb_grid3.best_params_['clf__gamma'],\n",
    "                    subsample=rexgb_grid4.best_params_['clf__subsample'],\n",
    "                    colsample_bytree=rexgb_grid4.best_params_['clf__colsample_bytree'],\n",
    "                    #reg_alpha=0.1,\n",
    "                    #reg_lambda=0.1,\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')\n",
    "\n",
    "select = SelectFromModel(rexgb_tune5,threshold='median')\n",
    "\n",
    "pipe5 = Pipeline([('select',select),('clf',rexgb_tune5)])\n",
    "\n",
    "kf5=KFold(n_splits=5,random_state=10)\n",
    "\n",
    "# parameters\n",
    "param_xgb5 = {\n",
    "    'clf__reg_alpha':[0.001,0.01,0.1,1,10,100],\n",
    "    'clf__reg_lambda':[0.001,0.01,0.1,1,10,100]\n",
    "}\n",
    "\n",
    "rexgb_grid5 = GridSearchCV(pipe5,\n",
    "                          param_grid=param_xgb5,\n",
    "                          cv=kf5)\n",
    "\n",
    "rexgb_grid5.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_result(rexgb_grid5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tunning 6 : Learning rate , n_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_tune6 = XGBRegressor(#learning_rate=0.25,\n",
    "                    n_estimators=rexgb_grid.best_params_['clf__n_estimators'], \n",
    "                    min_child_weight=rexgb_grid2.best_params_['clf__min_child_weight'],\n",
    "                    max_depth=rexgb_grid2.best_params_['clf__max_depth'],\n",
    "                    gamma=rexgb_grid3.best_params_['clf__gamma'],\n",
    "                    subsample=rexgb_grid4.best_params_['clf__subsample'],\n",
    "                    colsample_bytree=rexgb_grid4.best_params_['clf__colsample_bytree'],\n",
    "                    reg_alpha=rexgb_grid5.best_params_['clf__reg_alpha'],\n",
    "                    reg_lambda=rexgb_grid5.best_params_['clf__reg_lambda'],\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')\n",
    "\n",
    "select = SelectFromModel(rexgb_tune6,threshold='median')\n",
    "\n",
    "pipe6 = Pipeline([('select',select),('clf',rexgb_tune6)])\n",
    "\n",
    "kf5=KFold(n_splits=5,random_state=10)\n",
    "\n",
    "# parameters\n",
    "\n",
    "param_xgb6 = {\n",
    "    'clf__learning_rate':[0.25,0.12,0.1,0.05,0.01]}\n",
    "\n",
    "rexgb_grid6 = GridSearchCV(pipe6,\n",
    "                          param_grid=param_xgb6,\n",
    "                          cv=kf5)\n",
    "\n",
    "rexgb_grid6.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_grid6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_result(rexgb_grid6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rexgb_final = XGBRegressor(learning_rate=0.1,\n",
    "                    n_estimators=100, \n",
    "                    min_child_weight=1,\n",
    "                    max_depth=3,\n",
    "                    gamma=0.1,\n",
    "                    subample=0.9,\n",
    "                    colsample_bytree=0.6,\n",
    "                    reg_alpha=0.01,\n",
    "                    reg_lambda=10,\n",
    "                    random_state=10,\n",
    "                    objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(rexgb_final,kf5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Our First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(rexgb,kf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can see that R-Square CV has increased from 0.867 to 0.876. That is the best model\n",
    "\n",
    "Lets Prepare to predict the Submission Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the response\n",
    "y_pred=rexgb_final.predict(df_dummies_test[fitur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=rexgb_grid6.best_estimator_.predict(df_dummies_test[fitur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=rexgb_grid6.best_estimator_.predict(df_dummies_test[fitur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id':df_dummies_test['Id'],'SalePrice':y_pred},\n",
    "                          columns=['Id','SalePrice']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### i want to know some condition of the data. i want to know about MISSING VALUES, DATA TYPES, LIST OF VARIABLES. I also want to know about the unlabelled data since it needed to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR SELECTING CATEGORICAL AND NUMERICAL VARIABLE\n",
    "def categorical(df):\n",
    "    num=list(df.columns[df.dtypes=='object'])\n",
    "    return num\n",
    "    \n",
    "def numerical(df):\n",
    "    cat=list(df.columns[df.dtypes=='int64'])+list(df.columns[df.dtypes=='float64'])\n",
    "    return ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a790104a4b5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lenght of categorical variable :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cat = categorical(df)\n",
    "print(cat,'\\n')\n",
    "print('lenght of categorical variable :',len(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
